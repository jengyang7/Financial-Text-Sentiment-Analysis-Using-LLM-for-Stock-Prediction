{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Gemma 7B Comparison Across Agreement Levels\n",
    "\n",
    "This notebook fine-tunes Gemma-7B using different agreement levels from FinancialPhraseBank to compare the impact of data quality on model performance.\n",
    "\n",
    "## Agreement Levels:\n",
    "- **sentences_50agree**: ≥50% annotator agreement (4,846 sentences)\n",
    "- **sentences_66agree**: ≥66% annotator agreement (4,217 sentences) \n",
    "- **sentences_75agree**: ≥75% annotator agreement (3,453 sentences)\n",
    "- **sentences_allagree**: 100% annotator agreement (2,264 sentences)\n",
    "\n",
    "## Hypothesis:\n",
    "Higher agreement levels should lead to better model performance due to reduced label noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorboard (c:\\Users\\Jayden\\.venvs\\fyp-venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117\n",
    "%pip install -q -U transformers==4.38.2\n",
    "%pip install -q accelerate==0.32.0\n",
    "%pip install -q -i https://pypi.org/simple/ bitsandbytes\n",
    "%pip install -q -U datasets==2.16.1\n",
    "%pip install -q -U trl==0.7.11\n",
    "%pip install -q -U peft==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers==4.38.2\n",
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer, \n",
    "    BitsAndBytesConfig, \n",
    "    TrainingArguments, \n",
    "    pipeline, \n",
    "    logging\n",
    ")\n",
    "from datasets import Dataset, load_dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "import bitsandbytes as bnb\n",
    "from trl import SFTTrainer\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"transformers=={transformers.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    \"\"\"Clear GPU and CPU memory\"\"\"\n",
    "    print(\"Clearing memory...\")\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "    print(f\"GPU memory reserved: {torch.cuda.memory_reserved()/1024**3:.2f} GB\")\n",
    "\n",
    "def wait_and_clear(seconds=60):\n",
    "    \"\"\"Wait for specified seconds and clear memory\"\"\"\n",
    "    print(f\"Waiting {seconds} seconds...\")\n",
    "    time.sleep(seconds)\n",
    "    clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(agreement_level):\n",
    "    \"\"\"Load and prepare dataset for specific agreement level\"\"\"\n",
    "    print(f\"\\nLoading dataset: {agreement_level}...\")\n",
    "    \n",
    "    # Load the dataset from HuggingFace\n",
    "    dataset = load_dataset(\"takala/financial_phrasebank\", agreement_level)\n",
    "    \n",
    "    # Convert to pandas for easier manipulation\n",
    "    df = dataset['train'].to_pandas()\n",
    "    df = df.rename(columns={'sentence': 'text', 'label': 'sentiment'})\n",
    "    \n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Sentiment distribution:\")\n",
    "    sentiment_dist = df['sentiment'].value_counts()\n",
    "    print(sentiment_dist)\n",
    "    \n",
    "    return df, sentiment_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_splits(df, max_samples_per_class=300):\n",
    "    \"\"\"Create balanced train/val/test splits\"\"\"\n",
    "    # Calculate minimum class size\n",
    "    min_class_size = df['sentiment'].value_counts().min()\n",
    "    samples_per_class = min(max_samples_per_class, min_class_size)\n",
    "    \n",
    "    # Use 70% for training, 15% for validation, 15% for testing\n",
    "    train_size_per_class = int(samples_per_class * 0.7)\n",
    "    val_size_per_class = int(samples_per_class * 0.15)\n",
    "    test_size_per_class = samples_per_class - train_size_per_class - val_size_per_class\n",
    "    \n",
    "    print(f\"Split sizes per class: Train={train_size_per_class}, Val={val_size_per_class}, Test={test_size_per_class}\")\n",
    "    \n",
    "    X_train, X_val, X_test = [], [], []\n",
    "    \n",
    "    # Map integer labels to sentiment names\n",
    "    label_mapping = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "    \n",
    "    for sentiment_label in [0, 1, 2]:\n",
    "        sentiment_name = label_mapping[sentiment_label]\n",
    "        sentiment_data = df[df.sentiment == sentiment_label]\n",
    "        \n",
    "        if len(sentiment_data) == 0:\n",
    "            print(f\"Warning: No samples found for {sentiment_name} sentiment\")\n",
    "            continue\n",
    "        \n",
    "        # Sample the required number for this class\n",
    "        if len(sentiment_data) >= samples_per_class:\n",
    "            sampled_data = sentiment_data.sample(n=samples_per_class, random_state=42)\n",
    "        else:\n",
    "            sampled_data = sentiment_data\n",
    "            print(f\"Warning: Only {len(sentiment_data)} samples available for {sentiment_name}\")\n",
    "        \n",
    "        # Split the sampled data\n",
    "        if len(sampled_data) >= 3:  # Need at least 3 samples to split\n",
    "            temp_data, test_data = train_test_split(\n",
    "                sampled_data, \n",
    "                test_size=min(test_size_per_class, len(sampled_data)//3),\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            if len(temp_data) >= 2:\n",
    "                train_data, val_data = train_test_split(\n",
    "                    temp_data,\n",
    "                    test_size=min(val_size_per_class, len(temp_data)//2),\n",
    "                    random_state=42\n",
    "                )\n",
    "            else:\n",
    "                train_data = temp_data\n",
    "                val_data = pd.DataFrame()\n",
    "        else:\n",
    "            train_data = sampled_data\n",
    "            val_data = pd.DataFrame()\n",
    "            test_data = pd.DataFrame()\n",
    "        \n",
    "        if len(train_data) > 0:\n",
    "            X_train.append(train_data)\n",
    "        if len(val_data) > 0:\n",
    "            X_val.append(val_data)\n",
    "        if len(test_data) > 0:\n",
    "            X_test.append(test_data)\n",
    "    \n",
    "    # Combine and shuffle\n",
    "    X_train = pd.concat(X_train).sample(frac=1, random_state=10).reset_index(drop=True) if X_train else pd.DataFrame()\n",
    "    X_val = pd.concat(X_val).sample(frac=1, random_state=10).reset_index(drop=True) if X_val else pd.DataFrame()\n",
    "    X_test = pd.concat(X_test).sample(frac=1, random_state=10).reset_index(drop=True) if X_test else pd.DataFrame()\n",
    "    \n",
    "    print(f\"Final splits: Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}\")\n",
    "    \n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prompts(X_train, X_val, X_test, tokenizer):\n",
    "    \"\"\"Prepare training prompts\"\"\"\n",
    "    EOS_TOKEN = tokenizer.eos_token\n",
    "    label_mapping = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "    \n",
    "    def generate_prompt(data_point):\n",
    "        sentiment_text = label_mapping[data_point[\"sentiment\"]]\n",
    "        return f\"\"\"Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "                determine if it is positive, neutral, or negative, and return the answer as \n",
    "                the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\"\n",
    "\n",
    "                [{data_point[\"text\"]}] = {sentiment_text}\n",
    "                \"\"\".strip() + EOS_TOKEN\n",
    "\n",
    "    def generate_test_prompt(data_point):\n",
    "        return f\"\"\"Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "                determine if it is positive, neutral, or negative, and return the answer as \n",
    "                the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\"\n",
    "\n",
    "                [{data_point[\"text\"]}] = \n",
    "                \"\"\".strip()\n",
    "    \n",
    "    # Generate prompts\n",
    "    train_prompts = pd.DataFrame(X_train.apply(generate_prompt, axis=1), columns=[\"text\"])\n",
    "    val_prompts = pd.DataFrame(X_val.apply(generate_prompt, axis=1), columns=[\"text\"])\n",
    "    \n",
    "    # Test prompts and true labels\n",
    "    y_true = [label_mapping[label] for label in X_test['sentiment'].tolist()]\n",
    "    test_prompts = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"text\"])\n",
    "    \n",
    "    # Convert to HuggingFace datasets\n",
    "    train_data = Dataset.from_pandas(train_prompts)\n",
    "    eval_data = Dataset.from_pandas(val_prompts)\n",
    "    \n",
    "    return train_data, eval_data, test_prompts, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer():\n",
    "    \"\"\"Load fresh model and tokenizer\"\"\"\n",
    "    model_name = \"google/gemma-7b\"\n",
    "    \n",
    "    compute_dtype = getattr(torch, \"float16\")\n",
    "    \n",
    "    # Configure 4-bit quantization\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "    )\n",
    "    \n",
    "    # Load model\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=bnb_config, \n",
    "    )\n",
    "    \n",
    "    model.config.use_cache = False\n",
    "    model.config.pretraining_tp = 1\n",
    "    \n",
    "    # Load tokenizer\n",
    "    max_seq_length = 2048\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, max_seq_length=max_seq_length)\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, agreement_level):\n",
    "    \"\"\"Comprehensive evaluation function\"\"\"\n",
    "    labels = ['positive', 'neutral', 'negative']\n",
    "    mapping = {'positive': 2, 'neutral': 1, 'none': 1, 'negative': 0}\n",
    "    \n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "    \n",
    "    y_true_mapped = np.vectorize(map_func)(y_true)\n",
    "    y_pred_mapped = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RESULTS FOR {agreement_level.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f'Overall Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    unique_labels = set(y_true_mapped)\n",
    "    \n",
    "    class_accuracies = {}\n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true_mapped)) \n",
    "                         if y_true_mapped[i] == label]\n",
    "        label_y_true = [y_true_mapped[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred_mapped[i] for i in label_indices]\n",
    "        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        label_name = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}[label]\n",
    "        class_accuracies[label_name] = label_accuracy\n",
    "        print(f'{label_name} Accuracy: {label_accuracy:.3f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(\n",
    "        y_true=y_true_mapped, \n",
    "        y_pred=y_pred_mapped,\n",
    "        target_names=['Negative', 'Neutral', 'Positive'],\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(\n",
    "        y_true=y_true_mapped, \n",
    "        y_pred=y_pred_mapped,\n",
    "        target_names=['Negative', 'Neutral', 'Positive']\n",
    "    ))\n",
    "    \n",
    "    return {\n",
    "        'agreement_level': agreement_level,\n",
    "        'overall_accuracy': accuracy,\n",
    "        'class_accuracies': class_accuracies,\n",
    "        'classification_report': class_report,\n",
    "        'test_samples': len(y_true)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(test_prompts, model, tokenizer):\n",
    "    \"\"\"Prediction function\"\"\"\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(test_prompts)), desc=\"Predicting\"):\n",
    "        prompt = test_prompts.iloc[i][\"text\"]\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **input_ids, \n",
    "                max_new_tokens=1, \n",
    "                temperature=0.0,\n",
    "                do_sample=False\n",
    "            )\n",
    "        \n",
    "        result = tokenizer.decode(outputs[0])\n",
    "        answer = result.split(\"=\")[-1].lower().strip()\n",
    "        \n",
    "        if \"positive\" in answer:\n",
    "            y_pred.append(\"positive\")\n",
    "        elif \"negative\" in answer:\n",
    "            y_pred.append(\"negative\")\n",
    "        elif \"neutral\" in answer:\n",
    "            y_pred.append(\"neutral\")\n",
    "        else:\n",
    "            y_pred.append(\"none\")\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(model, tokenizer, train_data, eval_data, agreement_level):\n",
    "    \"\"\"Fine-tune model for specific agreement level\"\"\"\n",
    "    # LoRA configuration\n",
    "    peft_config = LoraConfig(\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0,\n",
    "        r=64,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                        \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    )\n",
    "    \n",
    "    # Training arguments\n",
    "    training_steps = len(train_data) // 8\n",
    "    eval_steps = max(training_steps // 10, 10)\n",
    "    \n",
    "    training_arguments = TrainingArguments(\n",
    "        output_dir=f\"logs_{agreement_level}\",\n",
    "        num_train_epochs=3,  # Reduced epochs for comparison\n",
    "        gradient_checkpointing=True,\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=8,\n",
    "        optim=\"paged_adamw_32bit\",\n",
    "        save_steps=0,\n",
    "        logging_steps=max(training_steps // 20, 5),\n",
    "        learning_rate=2e-4,\n",
    "        weight_decay=0.001,\n",
    "        fp16=True,\n",
    "        bf16=False,\n",
    "        max_grad_norm=0.3,\n",
    "        max_steps=-1,\n",
    "        warmup_ratio=0.03,\n",
    "        group_by_length=False,\n",
    "        evaluation_strategy='steps',\n",
    "        eval_steps=eval_steps,\n",
    "        eval_accumulation_steps=1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        report_to=\"tensorboard\",\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=eval_data,\n",
    "        peft_config=peft_config,\n",
    "        dataset_text_field=\"text\",\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=2048,\n",
    "        args=training_arguments,\n",
    "        packing=False,\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nStarting fine-tuning for {agreement_level}...\")\n",
    "    print(f\"Training samples: {len(train_data)}\")\n",
    "    print(f\"Validation samples: {len(eval_data)}\")\n",
    "    \n",
    "    # Start training\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save model\n",
    "    model_save_path = f\"../models/trained-gemma-{agreement_level}\"\n",
    "    trainer.model.save_pretrained(model_save_path)\n",
    "    print(f\"Model saved to: {model_save_path}\")\n",
    "    \n",
    "    return trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Comparison Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comparison across 4 agreement levels...\n",
      "Agreement levels: ['sentences_50agree', 'sentences_66agree', 'sentences_75agree', 'sentences_allagree']\n",
      "Clearing memory...\n",
      "GPU memory allocated: 0.00 GB\n",
      "GPU memory reserved: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "# Define agreement levels to test\n",
    "agreement_levels = [\n",
    "    \"sentences_50agree\",\n",
    "    \"sentences_66agree\", \n",
    "    \"sentences_75agree\",\n",
    "    \"sentences_allagree\"\n",
    "]\n",
    "\n",
    "# Store results\n",
    "all_results = []\n",
    "detailed_results = {}\n",
    "\n",
    "print(f\"Starting comparison across {len(agreement_levels)} agreement levels...\")\n",
    "print(f\"Agreement levels: {agreement_levels}\")\n",
    "\n",
    "# Clear initial memory\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROCESSING SENTENCES_50AGREE (1/4)\n",
      "================================================================================\n",
      "\n",
      "Loading dataset: sentences_50agree...\n",
      "Dataset shape: (4846, 2)\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "1    2879\n",
      "2    1363\n",
      "0     604\n",
      "Name: count, dtype: int64\n",
      "Split sizes per class: Train=210, Val=45, Test=45\n",
      "Final splits: Train=630, Val=135, Test=135\n",
      "\n",
      "Loading fresh model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a3c89aa6ad4e038326a3c52287377b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing baseline performance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 20/20 [00:04<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy on 20 samples: 0.600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac4a584b216480eaae806a99d623a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831492705940448d918c628ad0f2591a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for sentences_50agree...\n",
      "Training samples: 630\n",
      "Validation samples: 135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf72d9395a94e43b5963c3b9ecb5290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7753, 'grad_norm': 2.1528613567352295, 'learning_rate': 0.000125, 'epoch': 0.06}\n",
      "{'loss': 1.4162, 'grad_norm': 7.059887409210205, 'learning_rate': 0.00019996135574945544, 'epoch': 0.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d82cd5c78f941839cd8b2043100a6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.235414028167725, 'eval_runtime': 42.3383, 'eval_samples_per_second': 3.189, 'eval_steps_per_second': 0.402, 'epoch': 0.13}\n",
      "{'loss': 1.1484, 'grad_norm': 1.1082799434661865, 'learning_rate': 0.00019952695086820975, 'epoch': 0.19}\n",
      "{'loss': 1.0193, 'grad_norm': 1.278225302696228, 'learning_rate': 0.00019861194048993863, 'epoch': 0.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764d69a8bf524db9850f853ada755306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.6322758197784424, 'eval_runtime': 40.4586, 'eval_samples_per_second': 3.337, 'eval_steps_per_second': 0.42, 'epoch': 0.25}\n",
      "{'loss': 0.9916, 'grad_norm': 0.8759284615516663, 'learning_rate': 0.00019722074310645553, 'epoch': 0.32}\n",
      "{'loss': 0.9316, 'grad_norm': 0.766567587852478, 'learning_rate': 0.00019536007666806556, 'epoch': 0.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec285ca9d744371a6984129b97b5ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.611525774002075, 'eval_runtime': 40.5168, 'eval_samples_per_second': 3.332, 'eval_steps_per_second': 0.42, 'epoch': 0.38}\n",
      "{'loss': 0.9062, 'grad_norm': 0.7578486800193787, 'learning_rate': 0.00019303892614326836, 'epoch': 0.44}\n",
      "{'loss': 0.9142, 'grad_norm': 0.8973798155784607, 'learning_rate': 0.00019026850013126157, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce376d19faa8476497b16ed3dc02b730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.369481563568115, 'eval_runtime': 40.4892, 'eval_samples_per_second': 3.334, 'eval_steps_per_second': 0.42, 'epoch': 0.51}\n",
      "{'loss': 0.9045, 'grad_norm': 0.5756798386573792, 'learning_rate': 0.00018706217673675811, 'epoch': 0.57}\n",
      "{'loss': 0.7784, 'grad_norm': 0.650130033493042, 'learning_rate': 0.00018343543896848273, 'epoch': 0.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f39deb77325406e9e1270ad1389d25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.950406551361084, 'eval_runtime': 40.5139, 'eval_samples_per_second': 3.332, 'eval_steps_per_second': 0.42, 'epoch': 0.63}\n",
      "{'loss': 0.871, 'grad_norm': 0.5725348591804504, 'learning_rate': 0.00017940579997330165, 'epoch': 0.7}\n",
      "{'loss': 0.8963, 'grad_norm': 0.5672242045402527, 'learning_rate': 0.00017499271846702213, 'epoch': 0.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc84741330054a6b88687ada8c85a51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.308538436889648, 'eval_runtime': 40.4922, 'eval_samples_per_second': 3.334, 'eval_steps_per_second': 0.42, 'epoch': 0.76}\n",
      "{'loss': 0.7387, 'grad_norm': 0.4933378994464874, 'learning_rate': 0.0001702175047702382, 'epoch': 0.83}\n",
      "{'loss': 0.891, 'grad_norm': 0.7776598930358887, 'learning_rate': 0.00016510321790296525, 'epoch': 0.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b018f053da4e75bf94ad22033bf4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.332681179046631, 'eval_runtime': 40.4371, 'eval_samples_per_second': 3.339, 'eval_steps_per_second': 0.42, 'epoch': 0.89}\n",
      "{'loss': 0.8738, 'grad_norm': 0.7762870192527771, 'learning_rate': 0.00015967455423498387, 'epoch': 0.95}\n",
      "{'loss': 0.7396, 'grad_norm': 0.5276827812194824, 'learning_rate': 0.00015395772822958845, 'epoch': 1.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11dddff63894e1da9cb27ea73b6c380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2527530193328857, 'eval_runtime': 40.4719, 'eval_samples_per_second': 3.336, 'eval_steps_per_second': 0.42, 'epoch': 1.02}\n",
      "{'loss': 0.5781, 'grad_norm': 0.5705731511116028, 'learning_rate': 0.00014798034585661695, 'epoch': 1.08}\n",
      "{'loss': 0.6356, 'grad_norm': 0.6096354126930237, 'learning_rate': 0.00014177127128603745, 'epoch': 1.14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe171ef402844dc88ee80cda880ad7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6295926570892334, 'eval_runtime': 40.4381, 'eval_samples_per_second': 3.338, 'eval_steps_per_second': 0.42, 'epoch': 1.14}\n",
      "{'loss': 0.6093, 'grad_norm': 0.5657178163528442, 'learning_rate': 0.00013536048750581494, 'epoch': 1.21}\n",
      "{'loss': 0.5614, 'grad_norm': 0.6040478348731995, 'learning_rate': 0.00012877895153711935, 'epoch': 1.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdab33687e7a41e1ac7d3dbc8c70d386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.040938377380371, 'eval_runtime': 40.4247, 'eval_samples_per_second': 3.34, 'eval_steps_per_second': 0.421, 'epoch': 1.27}\n",
      "{'loss': 0.6427, 'grad_norm': 0.6794120669364929, 'learning_rate': 0.0001220584449460274, 'epoch': 1.33}\n",
      "{'loss': 0.7171, 'grad_norm': 0.8418689370155334, 'learning_rate': 0.0001152314203735805, 'epoch': 1.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d9133f1a7c41109fcd0bbb84de8c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.495939254760742, 'eval_runtime': 40.4302, 'eval_samples_per_second': 3.339, 'eval_steps_per_second': 0.42, 'epoch': 1.4}\n",
      "{'loss': 0.6115, 'grad_norm': 0.8697348237037659, 'learning_rate': 0.00010833084482529048, 'epoch': 1.46}\n",
      "{'loss': 0.5785, 'grad_norm': 0.4955008924007416, 'learning_rate': 0.00010139004047683151, 'epoch': 1.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60d5436372d4a298a0dda5a085228ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.329401969909668, 'eval_runtime': 40.4282, 'eval_samples_per_second': 3.339, 'eval_steps_per_second': 0.42, 'epoch': 1.52}\n",
      "{'loss': 0.6095, 'grad_norm': 0.847461462020874, 'learning_rate': 9.444252376465171e-05, 'epoch': 1.59}\n",
      "{'loss': 0.5485, 'grad_norm': 0.7011503577232361, 'learning_rate': 8.752184353851916e-05, 'epoch': 1.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75598fd320640ed875c16eb3947cdf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2928597927093506, 'eval_runtime': 40.4946, 'eval_samples_per_second': 3.334, 'eval_steps_per_second': 0.42, 'epoch': 1.65}\n",
      "{'loss': 0.6, 'grad_norm': 0.6665135622024536, 'learning_rate': 8.066141905754723e-05, 'epoch': 1.71}\n",
      "{'loss': 0.566, 'grad_norm': 0.6151303052902222, 'learning_rate': 7.389437861200024e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5bf452c8b740209b3ad2f7d1c107ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0917019844055176, 'eval_runtime': 40.5086, 'eval_samples_per_second': 3.333, 'eval_steps_per_second': 0.42, 'epoch': 1.78}\n",
      "{'loss': 0.6956, 'grad_norm': 0.5662703514099121, 'learning_rate': 6.725339955015777e-05, 'epoch': 1.84}\n",
      "{'loss': 0.5927, 'grad_norm': 0.7945682406425476, 'learning_rate': 6.0770550482731924e-05, 'epoch': 1.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df01c484dc8847b4bdd41a1c8752f3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0964395999908447, 'eval_runtime': 40.5266, 'eval_samples_per_second': 3.331, 'eval_steps_per_second': 0.419, 'epoch': 1.9}\n",
      "{'loss': 0.5669, 'grad_norm': 0.6821892857551575, 'learning_rate': 5.447713642681612e-05, 'epoch': 1.97}\n",
      "{'loss': 0.5383, 'grad_norm': 0.5944995880126953, 'learning_rate': 4.840354763714991e-05, 'epoch': 2.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae73a6d72e04acab2fbec7bee6c9790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2918949127197266, 'eval_runtime': 40.4569, 'eval_samples_per_second': 3.337, 'eval_steps_per_second': 0.42, 'epoch': 2.03}\n",
      "{'loss': 0.4032, 'grad_norm': 0.655983030796051, 'learning_rate': 4.257911285467754e-05, 'epoch': 2.1}\n",
      "{'loss': 0.3695, 'grad_norm': 1.3740296363830566, 'learning_rate': 3.7031957681048604e-05, 'epoch': 2.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfe50a6333f4581a631a0a4c0c06005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.03077507019043, 'eval_runtime': 40.5848, 'eval_samples_per_second': 3.326, 'eval_steps_per_second': 0.419, 'epoch': 2.16}\n",
      "{'loss': 0.3497, 'grad_norm': 0.6783967018127441, 'learning_rate': 3.178886876295578e-05, 'epoch': 2.22}\n",
      "{'loss': 0.3529, 'grad_norm': 0.9170962572097778, 'learning_rate': 2.6875164442149147e-05, 'epoch': 2.29}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a075f34f6cf44febd4dc4bc49169582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.944071054458618, 'eval_runtime': 40.4597, 'eval_samples_per_second': 3.337, 'eval_steps_per_second': 0.42, 'epoch': 2.29}\n",
      "{'loss': 0.3922, 'grad_norm': 0.8543192148208618, 'learning_rate': 2.2314572495745746e-05, 'epoch': 2.35}\n",
      "{'loss': 0.348, 'grad_norm': 0.7622824907302856, 'learning_rate': 1.8129115557213262e-05, 'epoch': 2.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060d786ed677466a840989ffb1055148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.8780148029327393, 'eval_runtime': 40.4449, 'eval_samples_per_second': 3.338, 'eval_steps_per_second': 0.42, 'epoch': 2.41}\n",
      "{'loss': 0.3503, 'grad_norm': 0.8458753228187561, 'learning_rate': 1.433900477131882e-05, 'epoch': 2.48}\n",
      "{'loss': 0.3446, 'grad_norm': 0.7818285226821899, 'learning_rate': 1.0962542196571634e-05, 'epoch': 2.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1582a91ef04667bc6ba8d1a0665bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.9033308029174805, 'eval_runtime': 40.4975, 'eval_samples_per_second': 3.334, 'eval_steps_per_second': 0.42, 'epoch': 2.54}\n",
      "{'loss': 0.3506, 'grad_norm': 0.9490656852722168, 'learning_rate': 8.016032426448817e-06, 'epoch': 2.6}\n",
      "{'loss': 0.3506, 'grad_norm': 0.9947255849838257, 'learning_rate': 5.5137038561761115e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160b8153f0444621a88333bdc1e8c0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.9194488525390625, 'eval_runtime': 40.4636, 'eval_samples_per_second': 3.336, 'eval_steps_per_second': 0.42, 'epoch': 2.67}\n",
      "{'loss': 0.3685, 'grad_norm': 0.9885782599449158, 'learning_rate': 3.467639975257997e-06, 'epoch': 2.73}\n",
      "{'loss': 0.4013, 'grad_norm': 0.8801100254058838, 'learning_rate': 1.88772101753929e-06, 'epoch': 2.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89e6c517ae64de38376ac9c701eb6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.9195425510406494, 'eval_runtime': 40.4703, 'eval_samples_per_second': 3.336, 'eval_steps_per_second': 0.42, 'epoch': 2.79}\n",
      "{'loss': 0.3561, 'grad_norm': 0.8704021573066711, 'learning_rate': 7.815762505632096e-07, 'epoch': 2.86}\n",
      "{'loss': 0.3641, 'grad_norm': 1.006036400794983, 'learning_rate': 1.545471346164007e-07, 'epoch': 2.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6752ed3f783848ecb929ffe95a66808b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.924083948135376, 'eval_runtime': 40.4914, 'eval_samples_per_second': 3.334, 'eval_steps_per_second': 0.42, 'epoch': 2.92}\n",
      "{'train_runtime': 2099.7948, 'train_samples_per_second': 0.9, 'train_steps_per_second': 0.111, 'train_loss': 0.6795015676408751, 'epoch': 2.97}\n",
      "Model saved to: ../models/trained-gemma-sentences_50agree\n",
      "\n",
      "Evaluating fine-tuned model on 135 test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 0/135 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "Predicting: 100%|██████████| 135/135 [00:27<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESULTS FOR SENTENCES_50AGREE\n",
      "============================================================\n",
      "Overall Accuracy: 0.859\n",
      "Negative Accuracy: 0.867\n",
      "Neutral Accuracy: 0.844\n",
      "Positive Accuracy: 0.867\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.97      0.87      0.92        45\n",
      "     Neutral       0.81      0.84      0.83        45\n",
      "    Positive       0.81      0.87      0.84        45\n",
      "\n",
      "    accuracy                           0.86       135\n",
      "   macro avg       0.87      0.86      0.86       135\n",
      "weighted avg       0.87      0.86      0.86       135\n",
      "\n",
      "\n",
      "✅ Completed sentences_50agree\n",
      "Final accuracy: 0.859\n",
      "Improvement over baseline: 0.259\n",
      "Waiting 60 seconds...\n",
      "Clearing memory...\n",
      "GPU memory allocated: 0.02 GB\n",
      "GPU memory reserved: 1.53 GB\n",
      "\n",
      "================================================================================\n",
      "PROCESSING SENTENCES_66AGREE (2/4)\n",
      "================================================================================\n",
      "\n",
      "Loading dataset: sentences_66agree...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f070d3963d4196b993fa39197c1087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/682k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e91dceb82c4902991062849011433b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/4217 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (4217, 2)\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "1    2535\n",
      "2    1168\n",
      "0     514\n",
      "Name: count, dtype: int64\n",
      "Split sizes per class: Train=210, Val=45, Test=45\n",
      "Final splits: Train=630, Val=135, Test=135\n",
      "\n",
      "Loading fresh model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c15dec09744907ab0ce90c3b816ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing baseline performance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 20/20 [00:03<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy on 20 samples: 0.700\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0062ca8c2c774d4585d1f0255d2e12c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80f4a10bd1f4d78bb272c4fe30b8e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for sentences_66agree...\n",
      "Training samples: 630\n",
      "Validation samples: 135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8de098d7c84f14abfaeb14d43ea427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7076, 'grad_norm': 2.1542627811431885, 'learning_rate': 0.000125, 'epoch': 0.06}\n",
      "{'loss': 1.5103, 'grad_norm': 4.750561237335205, 'learning_rate': 0.00019996135574945544, 'epoch': 0.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8aa0e179681423cbd93dad8ea879712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.02640962600708, 'eval_runtime': 199.4027, 'eval_samples_per_second': 0.677, 'eval_steps_per_second': 0.085, 'epoch': 0.13}\n",
      "{'loss': 1.131, 'grad_norm': 2.109680652618408, 'learning_rate': 0.00019952695086820975, 'epoch': 0.19}\n",
      "{'loss': 0.9349, 'grad_norm': 1.1098700761795044, 'learning_rate': 0.00019861194048993863, 'epoch': 0.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf72d2767fe04a23a20ac9bb06252e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.014948844909668, 'eval_runtime': 188.636, 'eval_samples_per_second': 0.716, 'eval_steps_per_second': 0.09, 'epoch': 0.25}\n",
      "{'loss': 0.8997, 'grad_norm': 0.8331458568572998, 'learning_rate': 0.00019722074310645553, 'epoch': 0.32}\n",
      "{'loss': 0.8715, 'grad_norm': 0.6664701700210571, 'learning_rate': 0.00019536007666806556, 'epoch': 0.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0bfc00e3b0405ea415a5cace65a7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.226595878601074, 'eval_runtime': 175.4024, 'eval_samples_per_second': 0.77, 'eval_steps_per_second': 0.097, 'epoch': 0.38}\n",
      "{'loss': 0.878, 'grad_norm': 0.8562365770339966, 'learning_rate': 0.00019303892614326836, 'epoch': 0.44}\n",
      "{'loss': 0.8807, 'grad_norm': 0.7893714308738708, 'learning_rate': 0.00019026850013126157, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469581c647de4733a8d5a2dfedda3d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.844292163848877, 'eval_runtime': 168.6373, 'eval_samples_per_second': 0.801, 'eval_steps_per_second': 0.101, 'epoch': 0.51}\n",
      "{'loss': 0.8249, 'grad_norm': 0.6834694743156433, 'learning_rate': 0.00018706217673675811, 'epoch': 0.57}\n",
      "{'loss': 0.8937, 'grad_norm': 0.8234925866127014, 'learning_rate': 0.00018343543896848273, 'epoch': 0.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22aef7e9c2f444aaa32f681a70c7f840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.610210418701172, 'eval_runtime': 186.0692, 'eval_samples_per_second': 0.726, 'eval_steps_per_second': 0.091, 'epoch': 0.63}\n",
      "{'loss': 0.9732, 'grad_norm': 0.7330573201179504, 'learning_rate': 0.00017940579997330165, 'epoch': 0.7}\n",
      "{'loss': 0.8364, 'grad_norm': 0.8210954070091248, 'learning_rate': 0.00017499271846702213, 'epoch': 0.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce2279a81cd4ed1a6919c771cf6a4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.56644868850708, 'eval_runtime': 185.0694, 'eval_samples_per_second': 0.729, 'eval_steps_per_second': 0.092, 'epoch': 0.76}\n",
      "{'loss': 0.8142, 'grad_norm': 0.7060080766677856, 'learning_rate': 0.0001702175047702382, 'epoch': 0.83}\n",
      "{'loss': 0.8501, 'grad_norm': 0.7035314440727234, 'learning_rate': 0.00016510321790296525, 'epoch': 0.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2be19d327e4aa2aa3b195b5297a195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.6381585597991943, 'eval_runtime': 186.7178, 'eval_samples_per_second': 0.723, 'eval_steps_per_second': 0.091, 'epoch': 0.89}\n",
      "{'loss': 0.8127, 'grad_norm': 0.6339845061302185, 'learning_rate': 0.00015967455423498387, 'epoch': 0.95}\n",
      "{'loss': 0.7462, 'grad_norm': 0.5305508971214294, 'learning_rate': 0.00015395772822958845, 'epoch': 1.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bba12b60ff433c9c6f9c7329fb16cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9566586017608643, 'eval_runtime': 184.5406, 'eval_samples_per_second': 0.732, 'eval_steps_per_second': 0.092, 'epoch': 1.02}\n",
      "{'loss': 0.6321, 'grad_norm': 0.6710834503173828, 'learning_rate': 0.00014798034585661695, 'epoch': 1.08}\n",
      "{'loss': 0.5961, 'grad_norm': 0.6381396055221558, 'learning_rate': 0.00014177127128603745, 'epoch': 1.14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9c5ed577b04a568e357a861fb268a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.6212563514709473, 'eval_runtime': 194.3682, 'eval_samples_per_second': 0.695, 'eval_steps_per_second': 0.087, 'epoch': 1.14}\n",
      "{'loss': 0.6298, 'grad_norm': 0.7598622441291809, 'learning_rate': 0.00013536048750581494, 'epoch': 1.21}\n",
      "{'loss': 0.6106, 'grad_norm': 0.6594679355621338, 'learning_rate': 0.00012877895153711935, 'epoch': 1.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d89fc1dcbc4d79a73ad524ef57e729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.6490116119384766, 'eval_runtime': 190.2341, 'eval_samples_per_second': 0.71, 'eval_steps_per_second': 0.089, 'epoch': 1.27}\n",
      "{'loss': 0.5946, 'grad_norm': 0.6872744560241699, 'learning_rate': 0.0001220584449460274, 'epoch': 1.33}\n",
      "{'loss': 0.6881, 'grad_norm': 0.7025502920150757, 'learning_rate': 0.0001152314203735805, 'epoch': 1.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ce7287139f40469b5f7e7422714690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.378303050994873, 'eval_runtime': 192.2249, 'eval_samples_per_second': 0.702, 'eval_steps_per_second': 0.088, 'epoch': 1.4}\n",
      "{'loss': 0.6109, 'grad_norm': 0.7040687203407288, 'learning_rate': 0.00010833084482529048, 'epoch': 1.46}\n",
      "{'loss': 0.5664, 'grad_norm': 0.532467782497406, 'learning_rate': 0.00010139004047683151, 'epoch': 1.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2973603d9d443c5a7957f9f87669731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.387423038482666, 'eval_runtime': 188.1066, 'eval_samples_per_second': 0.718, 'eval_steps_per_second': 0.09, 'epoch': 1.52}\n",
      "{'loss': 0.5488, 'grad_norm': 0.7776100635528564, 'learning_rate': 9.444252376465171e-05, 'epoch': 1.59}\n",
      "{'loss': 0.5784, 'grad_norm': 0.709304928779602, 'learning_rate': 8.752184353851916e-05, 'epoch': 1.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ffbb168bbc4eaba133ba447bb2cde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.827875852584839, 'eval_runtime': 185.9931, 'eval_samples_per_second': 0.726, 'eval_steps_per_second': 0.091, 'epoch': 1.65}\n",
      "{'loss': 0.6483, 'grad_norm': 0.8374121785163879, 'learning_rate': 8.066141905754723e-05, 'epoch': 1.71}\n",
      "{'loss': 0.6096, 'grad_norm': 0.7866350412368774, 'learning_rate': 7.389437861200024e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b392d1abfdb74692b155c98a63f4dc3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.621126651763916, 'eval_runtime': 192.965, 'eval_samples_per_second': 0.7, 'eval_steps_per_second': 0.088, 'epoch': 1.78}\n",
      "{'loss': 0.5907, 'grad_norm': 0.6101877689361572, 'learning_rate': 6.725339955015777e-05, 'epoch': 1.84}\n",
      "{'loss': 0.5799, 'grad_norm': 0.7361197471618652, 'learning_rate': 6.0770550482731924e-05, 'epoch': 1.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5af185dee2741d4b11d2962cd3e3a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.5515027046203613, 'eval_runtime': 192.4323, 'eval_samples_per_second': 0.702, 'eval_steps_per_second': 0.088, 'epoch': 1.9}\n",
      "{'loss': 0.5958, 'grad_norm': 0.8123001456260681, 'learning_rate': 5.447713642681612e-05, 'epoch': 1.97}\n",
      "{'loss': 0.4762, 'grad_norm': 0.4804086983203888, 'learning_rate': 4.840354763714991e-05, 'epoch': 2.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c553fdb52884e789caf21a33137f87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.6541905403137207, 'eval_runtime': 187.0767, 'eval_samples_per_second': 0.722, 'eval_steps_per_second': 0.091, 'epoch': 2.03}\n",
      "{'loss': 0.3773, 'grad_norm': 0.595813512802124, 'learning_rate': 4.257911285467754e-05, 'epoch': 2.1}\n",
      "{'loss': 0.4254, 'grad_norm': 1.4746308326721191, 'learning_rate': 3.7031957681048604e-05, 'epoch': 2.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed86aacaa6145bda25fba7ee8837d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.7535037994384766, 'eval_runtime': 185.9249, 'eval_samples_per_second': 0.726, 'eval_steps_per_second': 0.091, 'epoch': 2.16}\n",
      "{'loss': 0.3272, 'grad_norm': 1.0901398658752441, 'learning_rate': 3.178886876295578e-05, 'epoch': 2.22}\n",
      "{'loss': 0.4029, 'grad_norm': 0.8006512522697449, 'learning_rate': 2.6875164442149147e-05, 'epoch': 2.29}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5aebae5b34c4575bf201a7f689633a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.7597174644470215, 'eval_runtime': 195.4226, 'eval_samples_per_second': 0.691, 'eval_steps_per_second': 0.087, 'epoch': 2.29}\n",
      "{'loss': 0.3298, 'grad_norm': 0.7152491807937622, 'learning_rate': 2.2314572495745746e-05, 'epoch': 2.35}\n",
      "{'loss': 0.3491, 'grad_norm': 0.6010178923606873, 'learning_rate': 1.8129115557213262e-05, 'epoch': 2.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4783d496388473096e3ba571b3d90c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.7930080890655518, 'eval_runtime': 192.6026, 'eval_samples_per_second': 0.701, 'eval_steps_per_second': 0.088, 'epoch': 2.41}\n",
      "{'loss': 0.3473, 'grad_norm': 0.7069100737571716, 'learning_rate': 1.433900477131882e-05, 'epoch': 2.48}\n",
      "{'loss': 0.3491, 'grad_norm': 0.8636981844902039, 'learning_rate': 1.0962542196571634e-05, 'epoch': 2.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a171ca449148318db0af32e8f6acc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.8121564388275146, 'eval_runtime': 194.2038, 'eval_samples_per_second': 0.695, 'eval_steps_per_second': 0.088, 'epoch': 2.54}\n",
      "{'loss': 0.3261, 'grad_norm': 0.8348325490951538, 'learning_rate': 8.016032426448817e-06, 'epoch': 2.6}\n",
      "{'loss': 0.3247, 'grad_norm': 0.8679013848304749, 'learning_rate': 5.5137038561761115e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96188d40b22f44c4aa2a478b612b0ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.80822491645813, 'eval_runtime': 192.1458, 'eval_samples_per_second': 0.703, 'eval_steps_per_second': 0.088, 'epoch': 2.67}\n",
      "{'loss': 0.3694, 'grad_norm': 0.9941308498382568, 'learning_rate': 3.467639975257997e-06, 'epoch': 2.73}\n",
      "{'loss': 0.3428, 'grad_norm': 0.7783603072166443, 'learning_rate': 1.88772101753929e-06, 'epoch': 2.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cccf105fecd4434be8a9e3df2af30de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.809690237045288, 'eval_runtime': 186.3824, 'eval_samples_per_second': 0.724, 'eval_steps_per_second': 0.091, 'epoch': 2.79}\n",
      "{'loss': 0.3252, 'grad_norm': 0.7951807379722595, 'learning_rate': 7.815762505632096e-07, 'epoch': 2.86}\n",
      "{'loss': 0.4068, 'grad_norm': 1.1584914922714233, 'learning_rate': 1.545471346164007e-07, 'epoch': 2.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a40514dfeb741ab9efb151dca4f0e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.8103692531585693, 'eval_runtime': 190.4354, 'eval_samples_per_second': 0.709, 'eval_steps_per_second': 0.089, 'epoch': 2.92}\n",
      "{'train_runtime': 7124.3233, 'train_samples_per_second': 0.265, 'train_steps_per_second': 0.033, 'train_loss': 0.6706424752871195, 'epoch': 2.97}\n",
      "Model saved to: ../models/trained-gemma-sentences_66agree\n",
      "\n",
      "Evaluating fine-tuned model on 135 test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 135/135 [03:34<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESULTS FOR SENTENCES_66AGREE\n",
      "============================================================\n",
      "Overall Accuracy: 0.896\n",
      "Negative Accuracy: 0.933\n",
      "Neutral Accuracy: 0.867\n",
      "Positive Accuracy: 0.889\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.93      0.97        45\n",
      "     Neutral       0.83      0.87      0.85        45\n",
      "    Positive       0.87      0.89      0.88        45\n",
      "\n",
      "    accuracy                           0.90       135\n",
      "   macro avg       0.90      0.90      0.90       135\n",
      "weighted avg       0.90      0.90      0.90       135\n",
      "\n",
      "\n",
      "✅ Completed sentences_66agree\n",
      "Final accuracy: 0.896\n",
      "Improvement over baseline: 0.196\n",
      "Waiting 60 seconds...\n",
      "Clearing memory...\n",
      "GPU memory allocated: 0.02 GB\n",
      "GPU memory reserved: 1.53 GB\n",
      "\n",
      "================================================================================\n",
      "PROCESSING SENTENCES_75AGREE (3/4)\n",
      "================================================================================\n",
      "\n",
      "Loading dataset: sentences_75agree...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cf38cc73cb44cbbc895327a3fc4302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (3453, 2)\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "1    2146\n",
      "2     887\n",
      "0     420\n",
      "Name: count, dtype: int64\n",
      "Split sizes per class: Train=210, Val=45, Test=45\n",
      "Final splits: Train=630, Val=135, Test=135\n",
      "\n",
      "Loading fresh model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14abb8b290784c27ae8e6f9449c0507d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing baseline performance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 20/20 [00:03<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy on 20 samples: 0.600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d38b46043d146fcb237ebeaaa9aa9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cea6d3e893c4f7680c5cb4a743da49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for sentences_75agree...\n",
      "Training samples: 630\n",
      "Validation samples: 135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6626e4e5bc674611b78da74a482db658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7559, 'grad_norm': 2.2697901725769043, 'learning_rate': 0.000125, 'epoch': 0.06}\n",
      "{'loss': 1.4252, 'grad_norm': 5.801547527313232, 'learning_rate': 0.00019996135574945544, 'epoch': 0.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd43b3e969b244d0b54779f293756562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.3807244300842285, 'eval_runtime': 761.2046, 'eval_samples_per_second': 0.177, 'eval_steps_per_second': 0.022, 'epoch': 0.13}\n",
      "{'loss': 1.0738, 'grad_norm': 1.1775695085525513, 'learning_rate': 0.00019952695086820975, 'epoch': 0.19}\n",
      "{'loss': 1.0123, 'grad_norm': 1.0291610956192017, 'learning_rate': 0.00019861194048993863, 'epoch': 0.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5423d4ea845c49adaf12d6eca45edfb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.7285358905792236, 'eval_runtime': 771.5395, 'eval_samples_per_second': 0.175, 'eval_steps_per_second': 0.022, 'epoch': 0.25}\n",
      "{'loss': 0.8627, 'grad_norm': 0.8501899838447571, 'learning_rate': 0.00019722074310645553, 'epoch': 0.32}\n",
      "{'loss': 0.8763, 'grad_norm': 0.9155899882316589, 'learning_rate': 0.00019536007666806556, 'epoch': 0.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aee53312b60479fa9faa3097164683f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7896528244018555, 'eval_runtime': 992.3208, 'eval_samples_per_second': 0.136, 'eval_steps_per_second': 0.017, 'epoch': 0.38}\n",
      "{'loss': 0.8026, 'grad_norm': 0.8193289637565613, 'learning_rate': 0.00019303892614326836, 'epoch': 0.44}\n",
      "{'loss': 0.811, 'grad_norm': 1.1094731092453003, 'learning_rate': 0.00019026850013126157, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270eef21dcc64079b2ab868a1bd09881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7001962661743164, 'eval_runtime': 1121.9366, 'eval_samples_per_second': 0.12, 'eval_steps_per_second': 0.015, 'epoch': 0.51}\n",
      "{'loss': 0.9329, 'grad_norm': 0.8104057908058167, 'learning_rate': 0.00018706217673675811, 'epoch': 0.57}\n",
      "{'loss': 0.8977, 'grad_norm': 0.8204874396324158, 'learning_rate': 0.00018343543896848273, 'epoch': 0.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15dc6471be2f4308a0181df0d95c6e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.455503225326538, 'eval_runtime': 1124.2921, 'eval_samples_per_second': 0.12, 'eval_steps_per_second': 0.015, 'epoch': 0.63}\n",
      "{'loss': 0.7635, 'grad_norm': 0.6147134304046631, 'learning_rate': 0.00017940579997330165, 'epoch': 0.7}\n",
      "{'loss': 0.8839, 'grad_norm': 0.8285109996795654, 'learning_rate': 0.00017499271846702213, 'epoch': 0.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f656e48c1c6844e8b1bf37fbd7af4bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.719355821609497, 'eval_runtime': 1146.9288, 'eval_samples_per_second': 0.118, 'eval_steps_per_second': 0.015, 'epoch': 0.76}\n",
      "{'loss': 0.8476, 'grad_norm': 0.7275451421737671, 'learning_rate': 0.00017216960824649303, 'epoch': 0.83}\n",
      "{'loss': 0.838, 'grad_norm': 0.5734236240386963, 'learning_rate': 0.00016718807618570106, 'epoch': 0.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5db7a3624994019be4f69f032febe4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5927846431732178, 'eval_runtime': 1093.7436, 'eval_samples_per_second': 0.123, 'eval_steps_per_second': 0.016, 'epoch': 0.89}\n",
      "{'loss': 0.7605, 'grad_norm': 0.6987824440002441, 'learning_rate': 0.00016188209975614542, 'epoch': 0.95}\n",
      "{'loss': 0.7375, 'grad_norm': 0.7233102917671204, 'learning_rate': 0.00015627730097695638, 'epoch': 1.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934faebbe08f4fcd8e95ca96bde4f66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.43646502494812, 'eval_runtime': 1058.6111, 'eval_samples_per_second': 0.128, 'eval_steps_per_second': 0.016, 'epoch': 1.02}\n",
      "{'loss': 0.6329, 'grad_norm': 0.523972749710083, 'learning_rate': 0.00015040074484992, 'epoch': 1.08}\n",
      "{'loss': 0.6478, 'grad_norm': 0.6137544512748718, 'learning_rate': 0.00014428080866534396, 'epoch': 1.14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752928d8709b48ba99cfb8038f20b692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.699547290802002, 'eval_runtime': 1029.9835, 'eval_samples_per_second': 0.131, 'eval_steps_per_second': 0.017, 'epoch': 1.14}\n",
      "{'loss': 0.6861, 'grad_norm': 0.7580453753471375, 'learning_rate': 0.00013794704497101655, 'epoch': 1.21}\n",
      "{'loss': 0.6432, 'grad_norm': 0.6304428577423096, 'learning_rate': 0.00013143003886596669, 'epoch': 1.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d0126825ad4b6199b9ec05434b4df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.324995756149292, 'eval_runtime': 1051.0945, 'eval_samples_per_second': 0.128, 'eval_steps_per_second': 0.016, 'epoch': 1.27}\n",
      "{'loss': 0.6021, 'grad_norm': 0.6311206817626953, 'learning_rate': 0.00012476126030813963, 'epoch': 1.33}\n",
      "{'loss': 0.5776, 'grad_norm': 0.7232437133789062, 'learning_rate': 0.00011797291214917881, 'epoch': 1.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15b6aac1e5946c9974577d35cf33453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7622039318084717, 'eval_runtime': 1094.2857, 'eval_samples_per_second': 0.123, 'eval_steps_per_second': 0.016, 'epoch': 1.4}\n",
      "{'loss': 0.6298, 'grad_norm': 0.856391191482544, 'learning_rate': 0.00011109777463013915, 'epoch': 1.46}\n",
      "{'loss': 0.6007, 'grad_norm': 0.6362707018852234, 'learning_rate': 0.00010416904708904548, 'epoch': 1.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f236faabb2cd4eb29e33f9486e8940e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.368398427963257, 'eval_runtime': 1122.2814, 'eval_samples_per_second': 0.12, 'eval_steps_per_second': 0.015, 'epoch': 1.52}\n",
      "{'loss': 0.5362, 'grad_norm': 0.7105799317359924, 'learning_rate': 9.722018764467461e-05, 'epoch': 1.59}\n",
      "{'loss': 0.5641, 'grad_norm': 0.6604537963867188, 'learning_rate': 9.028475163071141e-05, 'epoch': 1.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40eb4d7b1894419b8dd142a4cfdca9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.437361717224121, 'eval_runtime': 1123.7999, 'eval_samples_per_second': 0.12, 'eval_steps_per_second': 0.015, 'epoch': 1.65}\n",
      "{'loss': 0.6096, 'grad_norm': 0.8567232489585876, 'learning_rate': 8.339622956046417e-05, 'epoch': 1.71}\n",
      "{'loss': 0.5945, 'grad_norm': 0.9001504778862, 'learning_rate': 7.658788540459062e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf8f9fbd2fc47dca15fe28e6370f997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5141549110412598, 'eval_runtime': 1084.071, 'eval_samples_per_second': 0.125, 'eval_steps_per_second': 0.016, 'epoch': 1.78}\n",
      "{'loss': 0.6695, 'grad_norm': 0.6156822443008423, 'learning_rate': 6.989259596277582e-05, 'epoch': 1.84}\n",
      "{'loss': 0.5759, 'grad_norm': 0.6438992619514465, 'learning_rate': 6.334269210501875e-05, 'epoch': 1.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abe307ad64e4edaa1d157fb9f1c8379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.608677387237549, 'eval_runtime': 1089.9293, 'eval_samples_per_second': 0.124, 'eval_steps_per_second': 0.016, 'epoch': 1.9}\n",
      "{'loss': 0.5909, 'grad_norm': 0.6954379677772522, 'learning_rate': 5.696980264915777e-05, 'epoch': 1.97}\n",
      "{'loss': 0.4618, 'grad_norm': 0.5764989256858826, 'learning_rate': 5.080470162853472e-05, 'epoch': 2.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d30d31b966c4410a05172ac5419f536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.851266384124756, 'eval_runtime': 1124.9149, 'eval_samples_per_second': 0.12, 'eval_steps_per_second': 0.015, 'epoch': 2.03}\n",
      "{'loss': 0.4068, 'grad_norm': 0.6058506965637207, 'learning_rate': 4.487715968732568e-05, 'epoch': 2.1}\n",
      "{'loss': 0.3663, 'grad_norm': 0.9526309370994568, 'learning_rate': 3.921580032113602e-05, 'epoch': 2.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6069697c0b6c40169e1462de1457cece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2406156063079834, 'eval_runtime': 1116.9907, 'eval_samples_per_second': 0.121, 'eval_steps_per_second': 0.015, 'epoch': 2.16}\n",
      "{'loss': 0.3267, 'grad_norm': 0.9221230745315552, 'learning_rate': 3.3847961657058845e-05, 'epoch': 2.22}\n",
      "{'loss': 0.3682, 'grad_norm': 0.8725353479385376, 'learning_rate': 2.879956444064703e-05, 'epoch': 2.29}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20892989edba440e911e570e77fa8801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.253580093383789, 'eval_runtime': 946.4538, 'eval_samples_per_second': 0.143, 'eval_steps_per_second': 0.018, 'epoch': 2.29}\n",
      "{'loss': 0.3938, 'grad_norm': 0.8309304714202881, 'learning_rate': 2.409498686727587e-05, 'epoch': 2.35}\n",
      "{'loss': 0.3397, 'grad_norm': 0.6865515112876892, 'learning_rate': 1.9756946862323545e-05, 'epoch': 2.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99ac999b69e403998b4142730541277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.224029541015625, 'eval_runtime': 940.161, 'eval_samples_per_second': 0.144, 'eval_steps_per_second': 0.018, 'epoch': 2.41}\n",
      "{'loss': 0.34, 'grad_norm': 0.8626471757888794, 'learning_rate': 1.580639237862608e-05, 'epoch': 2.48}\n",
      "{'loss': 0.3664, 'grad_norm': 0.8477368354797363, 'learning_rate': 1.2262400240949023e-05, 'epoch': 2.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad55c940594450a800cd060313abae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.242103338241577, 'eval_runtime': 953.967, 'eval_samples_per_second': 0.142, 'eval_steps_per_second': 0.018, 'epoch': 2.54}\n",
      "{'loss': 0.3386, 'grad_norm': 0.7671940922737122, 'learning_rate': 9.142084025945984e-06, 'epoch': 2.6}\n",
      "{'loss': 0.3573, 'grad_norm': 0.7648212909698486, 'learning_rate': 6.460511422441984e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9841937735464c1186977848a080c9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.269228219985962, 'eval_runtime': 939.1299, 'eval_samples_per_second': 0.144, 'eval_steps_per_second': 0.018, 'epoch': 2.67}\n",
      "{'loss': 0.3587, 'grad_norm': 0.8221639394760132, 'learning_rate': 4.230631471100655e-06, 'epoch': 2.73}\n",
      "{'loss': 0.3866, 'grad_norm': 0.8934240937232971, 'learning_rate': 2.4632120348272003e-06, 'epoch': 2.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe91189baa545849027c00e39dd6861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2673697471618652, 'eval_runtime': 944.1319, 'eval_samples_per_second': 0.143, 'eval_steps_per_second': 0.018, 'epoch': 2.79}\n",
      "{'loss': 0.3646, 'grad_norm': 0.8070080280303955, 'learning_rate': 1.1667878018564171e-06, 'epoch': 2.86}\n",
      "{'loss': 0.3651, 'grad_norm': 1.033717155456543, 'learning_rate': 3.4761907261356976e-07, 'epoch': 2.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab8c5aef1c64d44b004ad1ed8a5af35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.268368721008301, 'eval_runtime': 940.7441, 'eval_samples_per_second': 0.144, 'eval_steps_per_second': 0.018, 'epoch': 2.92}\n",
      "{'train_runtime': 80922.8707, 'train_samples_per_second': 0.023, 'train_steps_per_second': 0.003, 'train_loss': 0.6687080264091492, 'epoch': 2.97}\n",
      "Model saved to: ../models/trained-gemma-sentences_75agree\n",
      "\n",
      "Evaluating fine-tuned model on 135 test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 135/135 [18:48<00:00,  8.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESULTS FOR SENTENCES_75AGREE\n",
      "============================================================\n",
      "Overall Accuracy: 0.956\n",
      "Negative Accuracy: 0.956\n",
      "Neutral Accuracy: 0.956\n",
      "Positive Accuracy: 0.956\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.96      0.96      0.96        45\n",
      "     Neutral       0.93      0.96      0.95        45\n",
      "    Positive       0.98      0.96      0.97        45\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.96       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "\n",
      "✅ Completed sentences_75agree\n",
      "Final accuracy: 0.956\n",
      "Improvement over baseline: 0.356\n",
      "Waiting 60 seconds...\n",
      "Clearing memory...\n",
      "GPU memory allocated: 0.02 GB\n",
      "GPU memory reserved: 1.53 GB\n",
      "\n",
      "================================================================================\n",
      "PROCESSING SENTENCES_ALLAGREE (4/4)\n",
      "================================================================================\n",
      "\n",
      "Loading dataset: sentences_allagree...\n",
      "Dataset shape: (2264, 2)\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "1    1391\n",
      "2     570\n",
      "0     303\n",
      "Name: count, dtype: int64\n",
      "Split sizes per class: Train=210, Val=45, Test=45\n",
      "Final splits: Train=630, Val=135, Test=135\n",
      "\n",
      "Loading fresh model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507ea4b47a7b448e8b52ce3ceb1eb22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing baseline performance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 20/20 [00:03<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy on 20 samples: 0.650\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8db2ee48d28402091fbc1a9586f87c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf73026f90e441ca1322c398084f6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for sentences_allagree...\n",
      "Training samples: 630\n",
      "Validation samples: 135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802a616fb5ed439da19d46abbec60e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7024, 'grad_norm': 2.0866994857788086, 'learning_rate': 0.000125, 'epoch': 0.06}\n",
      "{'loss': 1.3267, 'grad_norm': 1.1144582033157349, 'learning_rate': 0.00019996135574945544, 'epoch': 0.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66eef5c5a81d495e823d452fb4e5b388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.551583766937256, 'eval_runtime': 301.8283, 'eval_samples_per_second': 0.447, 'eval_steps_per_second': 0.056, 'epoch': 0.13}\n",
      "{'loss': 0.9411, 'grad_norm': 2.4472694396972656, 'learning_rate': 0.00019952695086820975, 'epoch': 0.19}\n",
      "{'loss': 0.9481, 'grad_norm': 1.1820392608642578, 'learning_rate': 0.00019861194048993863, 'epoch': 0.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6649c60be6c47cdad961803b66cea6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3061013221740723, 'eval_runtime': 300.6065, 'eval_samples_per_second': 0.449, 'eval_steps_per_second': 0.057, 'epoch': 0.25}\n",
      "{'loss': 0.8817, 'grad_norm': 0.6980094313621521, 'learning_rate': 0.00019722074310645553, 'epoch': 0.32}\n",
      "{'loss': 0.8163, 'grad_norm': 0.7427102327346802, 'learning_rate': 0.00019536007666806556, 'epoch': 0.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b12ef7de9c4ea28a5345bc970e6533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.178292989730835, 'eval_runtime': 297.6257, 'eval_samples_per_second': 0.454, 'eval_steps_per_second': 0.057, 'epoch': 0.38}\n",
      "{'loss': 0.8266, 'grad_norm': 0.6613677144050598, 'learning_rate': 0.00019303892614326836, 'epoch': 0.44}\n",
      "{'loss': 0.7819, 'grad_norm': 0.7747270464897156, 'learning_rate': 0.00019026850013126157, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6906bacb16bd4c7aa3e3ba9086cf3da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.933924913406372, 'eval_runtime': 302.5757, 'eval_samples_per_second': 0.446, 'eval_steps_per_second': 0.056, 'epoch': 0.51}\n",
      "{'loss': 0.7099, 'grad_norm': 0.6444739699363708, 'learning_rate': 0.00018706217673675811, 'epoch': 0.57}\n",
      "{'loss': 0.731, 'grad_norm': 0.7612096667289734, 'learning_rate': 0.00018343543896848273, 'epoch': 0.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb680805b634ba79af385922920fe75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8503944873809814, 'eval_runtime': 298.676, 'eval_samples_per_second': 0.452, 'eval_steps_per_second': 0.057, 'epoch': 0.63}\n",
      "{'loss': 0.8121, 'grad_norm': 0.6304430365562439, 'learning_rate': 0.00017940579997330165, 'epoch': 0.7}\n",
      "{'loss': 0.7935, 'grad_norm': 0.8347581028938293, 'learning_rate': 0.00017499271846702213, 'epoch': 0.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f403697e41949bdb7107b2e95b23908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0055606365203857, 'eval_runtime': 298.3719, 'eval_samples_per_second': 0.452, 'eval_steps_per_second': 0.057, 'epoch': 0.76}\n",
      "{'loss': 0.7635, 'grad_norm': 0.6826755404472351, 'learning_rate': 0.0001702175047702382, 'epoch': 0.83}\n",
      "{'loss': 0.7505, 'grad_norm': 0.7690250873565674, 'learning_rate': 0.00016510321790296525, 'epoch': 0.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450b909d09374f5a8b0b6877172c273a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4949073791503906, 'eval_runtime': 298.3138, 'eval_samples_per_second': 0.453, 'eval_steps_per_second': 0.057, 'epoch': 0.89}\n",
      "{'loss': 0.8214, 'grad_norm': 0.7085044980049133, 'learning_rate': 0.00015967455423498387, 'epoch': 0.95}\n",
      "{'loss': 0.7042, 'grad_norm': 0.41645824909210205, 'learning_rate': 0.00015395772822958845, 'epoch': 1.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef4f5328aa14481bb9d58a21d5a794b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4369285106658936, 'eval_runtime': 297.0952, 'eval_samples_per_second': 0.454, 'eval_steps_per_second': 0.057, 'epoch': 1.02}\n",
      "{'loss': 0.5418, 'grad_norm': 0.47218045592308044, 'learning_rate': 0.00014798034585661695, 'epoch': 1.08}\n",
      "{'loss': 0.5467, 'grad_norm': 0.6585941910743713, 'learning_rate': 0.00014177127128603745, 'epoch': 1.14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ed9d18ff2042e9903dbb947d7215a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.226062059402466, 'eval_runtime': 299.6632, 'eval_samples_per_second': 0.451, 'eval_steps_per_second': 0.057, 'epoch': 1.14}\n",
      "{'loss': 0.5413, 'grad_norm': 0.5264376401901245, 'learning_rate': 0.00013536048750581494, 'epoch': 1.21}\n",
      "{'loss': 0.5813, 'grad_norm': 0.48963382840156555, 'learning_rate': 0.00012877895153711935, 'epoch': 1.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab94312dd4a4d0a89f9639157634160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7443692684173584, 'eval_runtime': 300.9069, 'eval_samples_per_second': 0.449, 'eval_steps_per_second': 0.056, 'epoch': 1.27}\n",
      "{'loss': 0.5874, 'grad_norm': 0.7128834128379822, 'learning_rate': 0.0001220584449460274, 'epoch': 1.33}\n",
      "{'loss': 0.5968, 'grad_norm': 0.6966096758842468, 'learning_rate': 0.0001152314203735805, 'epoch': 1.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcf924c76354b819c199eca71131003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8696184158325195, 'eval_runtime': 297.82, 'eval_samples_per_second': 0.453, 'eval_steps_per_second': 0.057, 'epoch': 1.4}\n",
      "{'loss': 0.5881, 'grad_norm': 0.6516638994216919, 'learning_rate': 0.00010833084482529048, 'epoch': 1.46}\n",
      "{'loss': 0.5017, 'grad_norm': 0.5505711436271667, 'learning_rate': 0.00010139004047683151, 'epoch': 1.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105df4016ebe437197a4bf1a085a6451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9633214473724365, 'eval_runtime': 299.1376, 'eval_samples_per_second': 0.451, 'eval_steps_per_second': 0.057, 'epoch': 1.52}\n",
      "{'loss': 0.5495, 'grad_norm': 0.7012750506401062, 'learning_rate': 9.444252376465171e-05, 'epoch': 1.59}\n",
      "{'loss': 0.5872, 'grad_norm': 0.6071786880493164, 'learning_rate': 8.752184353851916e-05, 'epoch': 1.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187969cc68be450e9e30341916cd67ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8263134956359863, 'eval_runtime': 297.604, 'eval_samples_per_second': 0.454, 'eval_steps_per_second': 0.057, 'epoch': 1.65}\n",
      "{'loss': 0.5084, 'grad_norm': 0.6189647912979126, 'learning_rate': 8.066141905754723e-05, 'epoch': 1.71}\n",
      "{'loss': 0.6158, 'grad_norm': 0.7965925335884094, 'learning_rate': 7.389437861200024e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf706b9d2f74b9db8d2602c63aa9185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6772215366363525, 'eval_runtime': 300.7085, 'eval_samples_per_second': 0.449, 'eval_steps_per_second': 0.057, 'epoch': 1.78}\n",
      "{'loss': 0.574, 'grad_norm': 0.5997666120529175, 'learning_rate': 6.725339955015777e-05, 'epoch': 1.84}\n",
      "{'loss': 0.5019, 'grad_norm': 0.5529484748840332, 'learning_rate': 6.0770550482731924e-05, 'epoch': 1.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0bf1c845a548678201c6504fe4c53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7246572971343994, 'eval_runtime': 297.9635, 'eval_samples_per_second': 0.453, 'eval_steps_per_second': 0.057, 'epoch': 1.9}\n",
      "{'loss': 0.5292, 'grad_norm': 0.697863757610321, 'learning_rate': 5.447713642681612e-05, 'epoch': 1.97}\n",
      "{'loss': 0.413, 'grad_norm': 0.4452820122241974, 'learning_rate': 4.840354763714991e-05, 'epoch': 2.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19896683da0b4b9bb2840dace978ed3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8784255981445312, 'eval_runtime': 299.1063, 'eval_samples_per_second': 0.451, 'eval_steps_per_second': 0.057, 'epoch': 2.03}\n",
      "{'loss': 0.3727, 'grad_norm': 0.49667060375213623, 'learning_rate': 4.257911285467754e-05, 'epoch': 2.1}\n",
      "{'loss': 0.3492, 'grad_norm': 0.9106413722038269, 'learning_rate': 3.7031957681048604e-05, 'epoch': 2.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5a8cdcc2f84c5ca74d7f2370ebd49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.298081398010254, 'eval_runtime': 298.6313, 'eval_samples_per_second': 0.452, 'eval_steps_per_second': 0.057, 'epoch': 2.16}\n",
      "{'loss': 0.3476, 'grad_norm': 0.8978917598724365, 'learning_rate': 3.178886876295578e-05, 'epoch': 2.22}\n",
      "{'loss': 0.3766, 'grad_norm': 0.7201527953147888, 'learning_rate': 2.6875164442149147e-05, 'epoch': 2.29}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d875702d52d4940837c6affb454a46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.1816036701202393, 'eval_runtime': 298.0978, 'eval_samples_per_second': 0.453, 'eval_steps_per_second': 0.057, 'epoch': 2.29}\n",
      "{'loss': 0.345, 'grad_norm': 0.6159949898719788, 'learning_rate': 2.2314572495745746e-05, 'epoch': 2.35}\n",
      "{'loss': 0.3525, 'grad_norm': 0.6905192136764526, 'learning_rate': 1.8129115557213262e-05, 'epoch': 2.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818cef11ef1a4c22881cdc340909b87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.1399388313293457, 'eval_runtime': 301.5172, 'eval_samples_per_second': 0.448, 'eval_steps_per_second': 0.056, 'epoch': 2.41}\n",
      "{'loss': 0.342, 'grad_norm': 0.6366906762123108, 'learning_rate': 1.433900477131882e-05, 'epoch': 2.48}\n",
      "{'loss': 0.3325, 'grad_norm': 0.943338930606842, 'learning_rate': 1.0962542196571634e-05, 'epoch': 2.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b00e857c76d43ad8647396eaaf195f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.189056158065796, 'eval_runtime': 299.3682, 'eval_samples_per_second': 0.451, 'eval_steps_per_second': 0.057, 'epoch': 2.54}\n",
      "{'loss': 0.3105, 'grad_norm': 0.7626591324806213, 'learning_rate': 8.016032426448817e-06, 'epoch': 2.6}\n",
      "{'loss': 0.3202, 'grad_norm': 0.7246250510215759, 'learning_rate': 5.5137038561761115e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35805e51882144d8b2ed5148e839b592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2168548107147217, 'eval_runtime': 299.3846, 'eval_samples_per_second': 0.451, 'eval_steps_per_second': 0.057, 'epoch': 2.67}\n",
      "{'loss': 0.3165, 'grad_norm': 0.7485545873641968, 'learning_rate': 3.467639975257997e-06, 'epoch': 2.73}\n",
      "{'loss': 0.3373, 'grad_norm': 0.6718629002571106, 'learning_rate': 1.88772101753929e-06, 'epoch': 2.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e628f6dd9e4771bb6f79b459fa4f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.226066827774048, 'eval_runtime': 297.9706, 'eval_samples_per_second': 0.453, 'eval_steps_per_second': 0.057, 'epoch': 2.79}\n",
      "{'loss': 0.3318, 'grad_norm': 0.8214324116706848, 'learning_rate': 7.815762505632096e-07, 'epoch': 2.86}\n",
      "{'loss': 0.3187, 'grad_norm': 0.7478442192077637, 'learning_rate': 1.545471346164007e-07, 'epoch': 2.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a50a85930e48d591c8e3edd6242ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.22692608833313, 'eval_runtime': 298.3111, 'eval_samples_per_second': 0.453, 'eval_steps_per_second': 0.057, 'epoch': 2.92}\n",
      "{'train_runtime': 15764.6666, 'train_samples_per_second': 0.12, 'train_steps_per_second': 0.015, 'train_loss': 0.6225597960317236, 'epoch': 2.97}\n",
      "Model saved to: ../models/trained-gemma-sentences_allagree\n",
      "\n",
      "Evaluating fine-tuned model on 135 test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 135/135 [04:13<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESULTS FOR SENTENCES_ALLAGREE\n",
      "============================================================\n",
      "Overall Accuracy: 0.978\n",
      "Negative Accuracy: 1.000\n",
      "Neutral Accuracy: 0.956\n",
      "Positive Accuracy: 0.978\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.96      1.00      0.98        45\n",
      "     Neutral       1.00      0.96      0.98        45\n",
      "    Positive       0.98      0.98      0.98        45\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "\n",
      "✅ Completed sentences_allagree\n",
      "Final accuracy: 0.978\n",
      "Improvement over baseline: 0.328\n",
      "\n",
      "🎉 Completed all 4 agreement levels!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, agreement_level in enumerate(agreement_levels):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PROCESSING {agreement_level.upper()} ({i+1}/{len(agreement_levels)})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Prepare dataset\n",
    "        df, sentiment_dist = prepare_dataset(agreement_level)\n",
    "        \n",
    "        # Step 2: Create splits\n",
    "        X_train, X_val, X_test = create_balanced_splits(df)\n",
    "        \n",
    "        if len(X_train) == 0 or len(X_test) == 0:\n",
    "            print(f\"Skipping {agreement_level} - insufficient data\")\n",
    "            continue\n",
    "        \n",
    "        # Step 3: Load fresh model and tokenizer\n",
    "        print(\"\\nLoading fresh model and tokenizer...\")\n",
    "        model, tokenizer = load_model_and_tokenizer()\n",
    "        \n",
    "        # Step 4: Prepare prompts\n",
    "        train_data, eval_data, test_prompts, y_true = prepare_prompts(X_train, X_val, X_test, tokenizer)\n",
    "        \n",
    "        # Step 5: Test baseline performance (quick test on subset)\n",
    "        print(\"\\nTesting baseline performance...\")\n",
    "        test_subset_size = min(20, len(test_prompts))  # Small subset for baseline\n",
    "        test_subset = test_prompts.head(test_subset_size)\n",
    "        true_subset = y_true[:test_subset_size]\n",
    "        \n",
    "        baseline_predictions = predict_sentiment(test_subset, model, tokenizer)\n",
    "        baseline_accuracy = accuracy_score(\n",
    "            np.vectorize(lambda x: {'positive': 2, 'neutral': 1, 'none': 1, 'negative': 0}.get(x, 1))(true_subset),\n",
    "            np.vectorize(lambda x: {'positive': 2, 'neutral': 1, 'none': 1, 'negative': 0}.get(x, 1))(baseline_predictions)\n",
    "        )\n",
    "        print(f\"Baseline accuracy on {test_subset_size} samples: {baseline_accuracy:.3f}\")\n",
    "        \n",
    "        # Step 6: Fine-tune model\n",
    "        fine_tuned_model = fine_tune_model(model, tokenizer, train_data, eval_data, agreement_level)\n",
    "        \n",
    "        # Step 7: Evaluate fine-tuned model\n",
    "        print(f\"\\nEvaluating fine-tuned model on {len(test_prompts)} test samples...\")\n",
    "        final_predictions = predict_sentiment(test_prompts, fine_tuned_model, tokenizer)\n",
    "        \n",
    "        # Step 8: Calculate metrics\n",
    "        results = evaluate_model(y_true, final_predictions, agreement_level)\n",
    "        results['baseline_accuracy'] = baseline_accuracy\n",
    "        results['dataset_size'] = len(df)\n",
    "        results['train_size'] = len(train_data)\n",
    "        results['timestamp'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        # Store results\n",
    "        all_results.append(results)\n",
    "        detailed_results[agreement_level] = {\n",
    "            'y_true': y_true,\n",
    "            'y_pred': final_predictions,\n",
    "            'test_data': X_test.copy()\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n✅ Completed {agreement_level}\")\n",
    "        print(f\"Final accuracy: {results['overall_accuracy']:.3f}\")\n",
    "        print(f\"Improvement over baseline: {results['overall_accuracy'] - baseline_accuracy:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {agreement_level}: {str(e)}\")\n",
    "        continue\n",
    "    \n",
    "    finally:\n",
    "        # Clean up memory after each model\n",
    "        if 'model' in locals():\n",
    "            del model\n",
    "        if 'tokenizer' in locals():\n",
    "            del tokenizer\n",
    "        if 'fine_tuned_model' in locals():\n",
    "            del fine_tuned_model\n",
    "        if 'trainer' in locals():\n",
    "            del trainer\n",
    "        \n",
    "        # Wait and clear memory between runs (except for the last one)\n",
    "        if i < len(agreement_levels) - 1:\n",
    "            wait_and_clear(60)\n",
    "\n",
    "print(f\"\\n🎉 Completed all {len(all_results)} agreement levels!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "COMPREHENSIVE RESULTS COMPARISON\n",
      "====================================================================================================\n",
      "      Agreement_Level  Dataset_Size  Train_Size  Test_Size  Baseline_Accuracy  \\\n",
      "0   sentences_50agree          4846         630        135               0.60   \n",
      "1   sentences_66agree          4217         630        135               0.70   \n",
      "2   sentences_75agree          3453         630        135               0.60   \n",
      "3  sentences_allagree          2264         630        135               0.65   \n",
      "\n",
      "   Final_Accuracy  Improvement  Improvement_Percent            Timestamp  \n",
      "0           0.859        0.259               43.210  2025-06-27 08:32:18  \n",
      "1           0.896        0.196               28.042  2025-06-27 10:37:32  \n",
      "2           0.956        0.356               59.259  2025-06-28 09:28:01  \n",
      "3           0.978        0.328               50.427  2025-06-28 13:57:57  \n",
      "\n",
      "📊 Results saved to: ../results/gemma_agreement_levels_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive results DataFrame\n",
    "if all_results:\n",
    "    comparison_df = pd.DataFrame([\n",
    "        {\n",
    "            'Agreement_Level': result['agreement_level'],\n",
    "            'Dataset_Size': result['dataset_size'],\n",
    "            'Train_Size': result['train_size'],\n",
    "            'Test_Size': result['test_samples'],\n",
    "            'Baseline_Accuracy': result['baseline_accuracy'],\n",
    "            'Final_Accuracy': result['overall_accuracy'],\n",
    "            'Improvement': result['overall_accuracy'] - result['baseline_accuracy'],\n",
    "            'Improvement_Percent': ((result['overall_accuracy'] - result['baseline_accuracy']) / result['baseline_accuracy']) * 100,\n",
    "            'Timestamp': result['timestamp']\n",
    "        }\n",
    "        for result in all_results\n",
    "    ])\n",
    "    \n",
    "    # Sort by agreement level for better display\n",
    "    level_order = ['sentences_50agree', 'sentences_66agree', 'sentences_75agree', 'sentences_allagree']\n",
    "    comparison_df['Level_Order'] = comparison_df['Agreement_Level'].apply(lambda x: level_order.index(x) if x in level_order else 999)\n",
    "    comparison_df = comparison_df.sort_values('Level_Order').drop('Level_Order', axis=1)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"COMPREHENSIVE RESULTS COMPARISON\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Display results table\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    print(comparison_df.round(3))\n",
    "    \n",
    "    # Save results\n",
    "    results_filename = \"../results/gemma_agreement_levels_comparison.csv\"\n",
    "    comparison_df.to_csv(results_filename, index=False)\n",
    "    print(f\"\\n📊 Results saved to: {results_filename}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No results to display - all experiments failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "KEY INSIGHTS AND ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "🏆 BEST PERFORMING MODEL:\n",
      "  Agreement Level: sentences_allagree\n",
      "  Final Accuracy: 0.978\n",
      "  Dataset Size: 2,264\n",
      "  Improvement: 0.328 (+50.4%)\n",
      "\n",
      "📉 LOWEST PERFORMING MODEL:\n",
      "  Agreement Level: sentences_50agree\n",
      "  Final Accuracy: 0.859\n",
      "  Dataset Size: 4,846\n",
      "  Improvement: 0.259 (+43.2%)\n",
      "\n",
      "📈 TRENDS ANALYSIS:\n",
      "  Average Final Accuracy: 0.922\n",
      "  Average Improvement: 0.285\n",
      "  Standard Deviation: 0.054\n",
      "\n",
      "🔍 CORRELATION ANALYSIS:\n",
      "  Agreement Level vs Final Accuracy Correlation: 0.939\n",
      "  ✅ Strong positive correlation - Higher agreement improves performance\n",
      "\n",
      "💡 RECOMMENDATIONS:\n",
      "  • Use sentences_allagree for production deployment\n",
      "  • Data quality vs quantity trade-off analysis completed\n",
      "  • Consider ensemble methods if performance differences are small\n",
      "  • Monitor real-world performance to validate these results\n"
     ]
    }
   ],
   "source": [
    "# Analyze trends and insights\n",
    "if all_results:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"KEY INSIGHTS AND ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Find best and worst performing models\n",
    "    best_model = comparison_df.loc[comparison_df['Final_Accuracy'].idxmax()]\n",
    "    worst_model = comparison_df.loc[comparison_df['Final_Accuracy'].idxmin()]\n",
    "    \n",
    "    print(f\"\\n🏆 BEST PERFORMING MODEL:\")\n",
    "    print(f\"  Agreement Level: {best_model['Agreement_Level']}\")\n",
    "    print(f\"  Final Accuracy: {best_model['Final_Accuracy']:.3f}\")\n",
    "    print(f\"  Dataset Size: {best_model['Dataset_Size']:,}\")\n",
    "    print(f\"  Improvement: {best_model['Improvement']:.3f} ({best_model['Improvement_Percent']:+.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n📉 LOWEST PERFORMING MODEL:\")\n",
    "    print(f\"  Agreement Level: {worst_model['Agreement_Level']}\")\n",
    "    print(f\"  Final Accuracy: {worst_model['Final_Accuracy']:.3f}\")\n",
    "    print(f\"  Dataset Size: {worst_model['Dataset_Size']:,}\")\n",
    "    print(f\"  Improvement: {worst_model['Improvement']:.3f} ({worst_model['Improvement_Percent']:+.1f}%)\")\n",
    "    \n",
    "    # Analyze relationship between agreement level and performance\n",
    "    print(f\"\\n📈 TRENDS ANALYSIS:\")\n",
    "    print(f\"  Average Final Accuracy: {comparison_df['Final_Accuracy'].mean():.3f}\")\n",
    "    print(f\"  Average Improvement: {comparison_df['Improvement'].mean():.3f}\")\n",
    "    print(f\"  Standard Deviation: {comparison_df['Final_Accuracy'].std():.3f}\")\n",
    "    \n",
    "    # Check if higher agreement correlates with better performance\n",
    "    agreement_mapping = {\n",
    "        'sentences_50agree': 50,\n",
    "        'sentences_66agree': 66,\n",
    "        'sentences_75agree': 75,\n",
    "        'sentences_allagree': 100\n",
    "    }\n",
    "    \n",
    "    comparison_df['Agreement_Percent'] = comparison_df['Agreement_Level'].map(agreement_mapping)\n",
    "    correlation = comparison_df['Agreement_Percent'].corr(comparison_df['Final_Accuracy'])\n",
    "    \n",
    "    print(f\"\\n🔍 CORRELATION ANALYSIS:\")\n",
    "    print(f\"  Agreement Level vs Final Accuracy Correlation: {correlation:.3f}\")\n",
    "    \n",
    "    if correlation > 0.5:\n",
    "        print(f\"  ✅ Strong positive correlation - Higher agreement improves performance\")\n",
    "    elif correlation > 0.2:\n",
    "        print(f\"  ✅ Moderate positive correlation - Higher agreement tends to improve performance\")\n",
    "    elif correlation > -0.2:\n",
    "        print(f\"  ⚠️  Weak correlation - Agreement level has minimal impact on performance\")\n",
    "    else:\n",
    "        print(f\"  ❌ Negative correlation - Unexpected result, may need investigation\")\n",
    "    \n",
    "    print(f\"\\n💡 RECOMMENDATIONS:\")\n",
    "    print(f\"  • Use {best_model['Agreement_Level']} for production deployment\")\n",
    "    print(f\"  • Data quality vs quantity trade-off analysis completed\")\n",
    "    print(f\"  • Consider ensemble methods if performance differences are small\")\n",
    "    print(f\"  • Monitor real-world performance to validate these results\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No analysis possible - no successful experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Detailed predictions saved: ../results/detailed_predictions_sentences_50agree.csv\n",
      "📝 Detailed predictions saved: ../results/detailed_predictions_sentences_66agree.csv\n",
      "📝 Detailed predictions saved: ../results/detailed_predictions_sentences_75agree.csv\n",
      "📝 Detailed predictions saved: ../results/detailed_predictions_sentences_allagree.csv\n",
      "\n",
      "✅ All results and analysis completed!\n",
      "📂 Check the ../results/ folder for all output files\n"
     ]
    }
   ],
   "source": [
    "# Save detailed results for each agreement level\n",
    "if detailed_results:\n",
    "    for agreement_level, data in detailed_results.items():\n",
    "        # Create detailed predictions DataFrame\n",
    "        detailed_df = pd.DataFrame({\n",
    "            'text': data['test_data']['text'].tolist(),\n",
    "            'true_sentiment': data['y_true'],\n",
    "            'predicted_sentiment': data['y_pred'],\n",
    "            'correct': [t == p for t, p in zip(data['y_true'], data['y_pred'])],\n",
    "            'agreement_level': agreement_level\n",
    "        })\n",
    "        \n",
    "        # Save detailed results\n",
    "        detail_filename = f\"../results/detailed_predictions_{agreement_level}.csv\"\n",
    "        detailed_df.to_csv(detail_filename, index=False)\n",
    "        print(f\"📝 Detailed predictions saved: {detail_filename}\")\n",
    "\n",
    "print(f\"\\n✅ All results and analysis completed!\")\n",
    "print(f\"📂 Check the ../results/ folder for all output files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing memory...\n",
      "GPU memory allocated: 0.02 GB\n",
      "GPU memory reserved: 1.53 GB\n",
      "\n",
      "🧹 Final memory cleanup completed\n",
      "\n",
      "🎯 Experiment completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Final memory cleanup\n",
    "clear_memory()\n",
    "print(\"\\n🧹 Final memory cleanup completed\")\n",
    "print(\"\\n🎯 Experiment completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
